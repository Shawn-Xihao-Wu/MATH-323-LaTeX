\documentclass[12pt]{article}
\usepackage{parskip} % no auto indent
\usepackage{graphicx} % graphics

% My marco file
\usepackage{mymarco}

% Begin page style
\usepackage[margin=1.0in]{geometry}
\usepackage{fancyhdr}
\pagestyle{fancy}
\setlength{\headheight}{15pt}
\rhead{36123040 Shawn Wu} % Define header
\lhead{MATH 323 HW 02} % Put assignment #
\cfoot{\thepage}

\begin{document}

% Problem 1
\begin{fproof}[Jacobson 2.3.2]
    First note that since \(R\) is commutative, then according to Jacobson on p.95, any main formulas on determinants on linear algebra over a field can be extended to that over \(R\), which means that \(\det: M_n(R) \to R\) is a homomorphism.
    Therefore, since \(AB = 1\), 
    \begin{align*}
        1 = \det(1)= \det(AB) = \det(A) \det(B) = \det(B)\det(A)
    \end{align*}
    This means that \(\det(B)\) is invertible in \(R\).
    And by Theorem 2.1 in Jacobson,
    \(B\) is invertible.
    Since \(AB = 1\), \(B\) is invertible in \(M_n(R)\), then \(B^{-1} = A\), as multiplicative inverse is unique.
    Therefore, \(BA = AB = 1\).
\end{fproof}
\newpage

% Problem 2
\begin{fproof}[Jacobson 2.4.5]
    Pick any \(\alpha_1 + \alpha_2\vi + \alpha_3 \vj + \alpha_4\vk\), \(\beta_1 + \beta_2\vi + \beta_3 \vj + \beta_4\vk \in I\).
    We first show that \((I, +, 0)\) is a subgroup of \(\mathbb{H}\).
    Note that
    \begin{align*}
        &(\alpha_1 + \alpha_2\vi + \alpha_3 \vj + \alpha_4\vk) - (\beta_1 + \beta_2\vi + \beta_3 \vj + \beta_4\vk \in I)\\
        =&(\alpha_1 - \beta_1) + (\alpha_2 - \beta_2)\vi + (\alpha_3 - \beta_3)\vj + (\alpha_4 - \beta_4)\vk.
    \end{align*}
    \textbf{Case 1:}
    If all of \(\alpha_i\) and \(\beta_i\) are integers, then all \(\alpha_i - \beta_i\) are integers as well.

    \textbf{Case 2:}
    If all of \(\alpha_i\) and \(\beta_i\) are halfs of odd integers, then clearly \(\alpha_i - \beta_i\) are integers as well.

    \textbf{Case 3:}
    If all \(\alpha_i\) are integers but all \(\beta_i\) are halfs of odd integers,
    then clearly all \(\alpha_i - \beta_i\) are halfs of integers as well.

    \textbf{Case 4:}
    If all \(\alpha_i\) are halfs of odd integers but all \(\beta_i\) are integers.
    This cases is similar to Case 3. All \(\alpha_i - \beta_i\) are halfs of integers.

    Therefore, by subgroup criteria, \((I, +, 0)\) is indeed a subgroup of \(\H\).

    Next we show that \((I, \cdot, 1)\) is a submonoid of \(\H\).
    First note that \(1 \in I\) as \(1 = 1 + 0\vi + 0\vj + 0\vk\) and \(0 \in \mathbb{Z}\).
    It remains to check that \(I\) is closed under multiplication.
    Note that
    \begin{align*}
        &(\alpha_1 + \alpha_2\vi + \alpha_3 \vj + \alpha_4\vk)(\beta_1 + \beta_2\vi + \beta_3 \vj + \beta_4\vk)\\
        &=\alpha_1 \beta_1 - \alpha_2 \beta_2 - \alpha_3 \beta_3 - \alpha_4 \beta_4\\
        & +(\alpha_1 \beta_2 + \alpha_2 \beta_1 + \alpha_3 \beta_4 - \alpha_4 \beta_3)\vi\\
        & +(\alpha_1 \beta_3 - \alpha_2 \beta_4 + \alpha_3 \beta_1 + \alpha_4 \beta_2)\vj\\
        & +(\alpha_1 \beta_4 + \alpha_2 \beta_3 - \alpha_3 \beta_2 + \alpha_4 \beta_1)\vk.
    \end{align*}

    \textbf{Case 1:}
    If all \(\alpha_i\) and \(\beta_i\) are integers, then clearly all coefficients \(\vi, \vj, \vj\) and the constant coefficients are integers as well.

    \textbf{Case 2:} If all \(\alpha_i\) and \(\beta_i\) are halfs of odd integers.
    Note that since each of four coefficients is in the form of \(\sum \alpha_{i'} \beta_{j'}\), and with how the plus and minus operations are arranged, it's clear that each coefficients are halfs of integers.

    \textbf{Case 3:} If all \(\alpha_i\) are integers but all \(\beta_i\) are halfs of integers.
    Then each \(\alpha_{i'}\beta_{j'}\) is either an integer of a half of an odd integer, depending on the parity of \(\alpha_{i'}\).
    And each coefficients must be either an integer of a half of an odd integer as well, as it is a sum of integers or halfs of odd integers.

    \textbf{Case 4:} If all \(\alpha_i\) are halfs of odd integers but all \(\beta_i\) are integers. This is similar to Case 3, and the same conclusion can be drawn.

    Therefore, all four cases have \((\alpha_1 + \alpha_2\vi + \alpha_3 \vj + \alpha_4\vk)(\beta_1 + \beta_2\vi + \beta_3 \vj + \beta_4\vk) \in I\).
    \((I, +, \cdot)\) is a subring of \(\H\).

    \begin{center}
        \(\ast~\ast~\ast\)
    \end{center}

    This is unfortunately NOT a division ring as not every element has an inverse.
    Consider the element \(\vi + \vj + \vk \in I\), then its inverse in \(\H\),
    \begin{align*}
        (\vi + \vj + \vk)^{-1}  = \frac{1}{0^2+1^2+1^2+1^2}(-\vi-\vj-\vk) = -\frac{1}{3}\vi - \frac{1}{3} \vj - \frac{1}{3} \vk.
    \end{align*}
    However, \(-1/3\) is neither an integer of a half of an odd integer.

    \begin{center}
        \(\ast~\ast~\ast\)
    \end{center}
    
    Note that for any \(x = \alpha_1 + \alpha_2\vi + \alpha_3 \vj + \alpha_4\vk \in I\),
    \(N(x) = \alpha_1^2 + \alpha_2^2 + \alpha_3^2 + \alpha_4^2\).
    If all \(\alpha_i\) are integers, then clearly \(N(x)\) is an integer as well.
    If however, \(\alpha_i\) are all halfs of odd integers, then for some \(\alpha_i' \in \mathbb{Z}\),
    \begin{align*}
        N(x) &= (\alpha_1' + 1/2)^2 + (\alpha_2' + 1/2)^2 + (\alpha_3' + 1/2)^2 + (\alpha_4' + 1/2)^2\\
        &= [(\alpha_1')^2 + 2 \alpha_1' + 1/4] + [(\alpha_2')^2 + 2 \alpha_2' + 1/4] + [(\alpha_3')^2 + 2 \alpha_3' + 1/4] + [(\alpha_4')^2 + 2 \alpha_4' + 1/4]\\
        &= (\alpha_1')^2 + 2 \alpha_1 + (\alpha_2')^2 + 2 \alpha_2' + (\alpha_3')^2 + 2 \alpha_3' + (\alpha_4')^2 + 2 \alpha_4' + 1\\
        & \in \mathbb{Z}.
    \end{align*}
    Now, clearly \(T(x) = 2 \alpha_1 \in \mathbb{Z}\) regardless if \(\alpha_1\) is an integer of a half of an odd integer.

    \begin{center}
        \(\ast~\ast~\ast\)
    \end{center}

    Note that by Ex.3 on p.100 of Jacobson, \(N(xy) = N(x)N(y)\) for \(x,y \in \H\).
    This means that \(N: \H \to \R_{\geq 0}\) is a homomorphism.
    Therefore, if \(x\) is a unit in \(I\), then \(1 = N(1) = N(x)N(x^{-1})\).
    Since \(N(x), N(x^{-1}) \in I\) by the above results, \(N(x) = 1\).
    Therefore, the subset of \(I\) that satisfy such condition is
    \begin{align*}
        \pm 1, \pm \vi, \pm \vj, \pm \vk, \frac{1}{2}(1 \pm \vi \pm \vj \pm \vk),
    \end{align*}
    and they are all units as their inverses in \(\H\) are in \(I\) as well.
    

\end{fproof}
\newpage

% Problem 3
\begin{fproof}[Jacobson 2.5.2]
  We first show that \((IJ)K \subseteq I(JK)\).
  Pick any element \(x \in (IJ)K\).
  Then,
  \begin{align*}
    x = d_1c_1 + d_2c_2 + \cdots + d_{m}c_{m},
  \end{align*}
  where \(m \in \mathbb{N}\), and \(d_1, \cdots, d_{m} \in IJ\),\( c_1, \cdots, c_{m} \in K\).
  Also note that for each \(i = 1, \cdots, m\).
  \(d_i = a_1b_1 + a_2b_2 + \cdots + a_{t_i}b_{t_i}\) where \(t_i \in \mathbb{N}\), \(a_1, \cdots, a_{t_i} \in I\), \(b_1, \cdots, b_{t_i} \in J\).
  Therefore,
  \begin{align*}
    x &= d_1c_1 + d_2c_2 + \cdots + d_{m}c_{m}\\
    &= \sum_{j=1}^{t_1} a_jb_jc_1 + \sum_{j=1}^{t_2} a_jb_jc_2 + \cdots + \sum_{j=1}^{t_m} a_jb_jc_m\\
    &= \sum_{j=1}^{t_1} a_j(b_jc_1) + \sum_{j=1}^{t_2} a_j(b_jc_2) + \cdots + \sum_{j=1}^{t_m} a_j(b_jc_m).
  \end{align*}
  Note that each \(b_jc_i\) is an element of \(JK\).
  Therefore, the above sum is in the finite sum of products elements of \(I\) with elements of \(JK\).
  Therefore, \(x \in I(JK)\).
  And with a similar reasoning on the associativity of multiplication of the ring, we get that \((IJ)K \supseteq I(JK)\).
\end{fproof}
\newpage

% Problem 4
\begin{fproof}[Jacobson 2.5.3]
    
\end{fproof}
\newpage

% Problem 5
\begin{fproof}[Jacobson 2.6.4]

\end{fproof}
\newpage

% Problem 6
\begin{fproof}[Jacobson 2.7.2]

\end{fproof}
\newpage

% Problem 7
\begin{fproof}[Jacobson 2.7.4]
  Fix a prime \(p\).
  Let's name the endomorphism \(a \mapsto a^{p}\) as \(\eta\).
  We show that \(\eta(1) = 1\), \(\eta(a+b) = \eta(a)+ \eta(b)\), and \(\eta(ab) = \eta(a)\eta(b)\) for any \(a,b \in R\).

  Let \(a,b \in R\) be arbitrary.
  First note that \(1^p = 1\). Hence \(\eta\) fixes the multiplicative identity.
  And since \(R\) is commutative, \((ab)^p = a^p \cdot b^p\) by permuting all the \(b\)'s to the left.

  Also note that for \(1 \leq k \leq p-1\),
  \begin{align*}
    \binom{p}{k} = \frac{p!}{k!(p-k)!} = p \cdot \frac{(p-1)!}{k!(p-k)!}.
  \end{align*}
  Since none of the factors of \(k!\) and \((p-k)!\) divide \(p\), \(p \mid \binom{p}{k}\). This means that for all \(1 \leq k \leq p-1\) and for all \(x \in R\),
  \begin{align*}
    \binom{p}{k}x = (mp)x = m(px) = m(0) = 0,
  \end{align*}
  for some integer \(m\).
  Therefore,
  \begin{align*}
    (a+b)^p &= \sum_{i=0}^{p} \binom{p}{k} a^{p-i}b^{i}\\
    & = a^p + \binom{p}{1}a^{p-1}b + \cdots + \binom{p}{p-1}ab^{p-1} + b^p\\
    & = a^p + b^p.
  \end{align*}
  This concludes the proof that \(\eta\) is an endomorphism.
  \begin{center}
    \(\ast~\ast~\ast\)
  \end{center}
  \(\eta\) is NOT an automorphism on \(R\). Here is a counter-example.

\end{fproof}
\newpage

% Problem 8
\begin{fproof}[Jacobson 2.7.9]

\end{fproof}
\newpage

% Problem 9
\begin{fproof}[Jacobson 2.7.10]

\end{fproof}
\end{document}